<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://tomfluff.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://tomfluff.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-13T14:32:14+00:00</updated><id>https://tomfluff.github.io/feed.xml</id><title type="html">blank</title><subtitle>Yotam Sechayk is a PhD candidate at the University of Tokyo, working on HCI and accessibility research. </subtitle><entry><title type="html">VeasyGuide at ASSETS 2025 Recap and Presentation Recording üé•</title><link href="https://tomfluff.github.io/blog/2025/veasyguide-assets-2025/" rel="alternate" type="text/html" title="VeasyGuide at ASSETS 2025 Recap and Presentation Recording üé•"/><published>2025-11-12T14:00:00+00:00</published><updated>2025-11-12T14:00:00+00:00</updated><id>https://tomfluff.github.io/blog/2025/veasyguide-assets-2025</id><content type="html" xml:base="https://tomfluff.github.io/blog/2025/veasyguide-assets-2025/"><![CDATA[<div class="d-none"> <a class="citation" href="#sechayk2025veasyguide">(Sechayk et al., 2025; Mohanbabu et al., 2025; Pimenova et al., 2025)</a> </div> <p>In the beautiful Denver, I had the privilege of presenting our work <em>‚Äú<a href="https://veasyguide.github.io/">VeasyGuide</a>: Personalized Visual Guidance for Low-vision Learners on Instructor Actions in Presentation Videos‚Äù</em> at <a href="https://assets25.sigaccess.org/">ASSETS 2025</a> (International ACM SIGACCESS Conference on Computers and Accessibility). Even more exciting, VeasyGuide won a üèÜ <strong>best paper honorable mention award!</strong></p> <p>This presentation marked an important milestone in my research on making learning accessible for low-vision learners. Plus, this was my first time attending ASSETS! In this post I will share my experience at ASSETS, and around Denver during my time there.</p> <blockquote class="block-note"> <p>Feel free to jump ahead to see the <a href="#recording">full recording of my presentation</a>.</p> </blockquote> <p>I didn‚Äôt know that VeasyGuide won an award. One morning, all of a sudden, I am getting <em>‚ÄúCongradulations!‚Äù</em> messages from friends. Seems like when they go over the online program they saw it. But I, I was oblivious to it! So it was such a nice surprise to wake up one day and realize that we have gotten an award. But let‚Äôs get back on track‚Äîthe conference!</p> <div class="row justify-content-center"> <div class="col-md-10"> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/assets-25-img-building-1-Medium-768-480.webp 480w,/assets/img/posts/assets-25-img-building-1-Medium-768-800.webp 800w,/assets/img/posts/assets-25-img-building-1-Medium-768-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/assets-25-img-building-1-Medium-768.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/assets-25-img-building-2-Medium-768-480.webp 480w,/assets/img/posts/assets-25-img-building-2-Medium-768-800.webp 800w,/assets/img/posts/assets-25-img-building-2-Medium-768-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/assets-25-img-building-2-Medium-768.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The venue of the conference, the Curtis Hotel at Denver. </div> </div> </div> <p>This year the conference was held at the Curtis Hotel in Denver, Colorado. I‚Äôve never been to Denver before, but I really liked that city. The downtown had a very nice vibe to it, and also some free public transportation! The shuttle that goes along the 16th street was free to use, which is so nice to see. I usually stay in hostels, which are not always near to the conference venue, so a freee shuttle but was a very nice surprise. The free shuttle goes from the big train station (Union) all the way down almost to the publuc library!</p> <div class="row justify-content-center"> <div class="col-md-10"> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/assets-25-img-denver-1-Medium-768-480.webp 480w,/assets/img/posts/assets-25-img-denver-1-Medium-768-800.webp 800w,/assets/img/posts/assets-25-img-denver-1-Medium-768-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/assets-25-img-denver-1-Medium-768.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/assets-25-img-denver-2-Medium-768-480.webp 480w,/assets/img/posts/assets-25-img-denver-2-Medium-768-800.webp 800w,/assets/img/posts/assets-25-img-denver-2-Medium-768-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/assets-25-img-denver-2-Medium-768.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Cool alleyway around 16th street in Denver. So much art around these places that people usually go in to. I think it's great to see this, it's an opportunity to bring life to these kind of areas! </div> </div> </div> <p>I took the opportunity to also visit the library. It is a very pleasant building, with a vintage kind of atmosphere. I sat down to do some work, at some random location, and as I am getting up to leave. I stumbled on a very interesting sign. And by <em>interesting</em> I mean, very relevant to me!</p> <div class="row justify-content-center"> <div class="col-md-10"> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/assets-25-img-library-1-Medium-768-480.webp 480w,/assets/img/posts/assets-25-img-library-1-Medium-768-800.webp 800w,/assets/img/posts/assets-25-img-library-1-Medium-768-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/assets-25-img-library-1-Medium-768.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The sign at the library pointing to the "Large Print" books section. </div> </div> </div> <p>I was sitting right next to the <strong>large print area!</strong> What an interesting coicidence right? So I decided to look around through the books there, and I noticed something. The visual style of all books did not exactly match. Some books used a larger font and some smaller. I wonder if there are any regulations on large print books? I tried capturing some of the books I saw there. I think it‚Äôs not that easy to notice the side difference in pictures, but when I was there looking at these books, it was a much clearer difference.</p> <div class="row justify-content-center"> <div class="col-md-10"> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/assets-25-img-library-2-Medium-768-480.webp 480w,/assets/img/posts/assets-25-img-library-2-Medium-768-800.webp 800w,/assets/img/posts/assets-25-img-library-2-Medium-768-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/assets-25-img-library-2-Medium-768.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/assets-25-img-library-3-Medium-768-480.webp 480w,/assets/img/posts/assets-25-img-library-3-Medium-768-800.webp 800w,/assets/img/posts/assets-25-img-library-3-Medium-768-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/assets-25-img-library-3-Medium-768.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/assets-25-img-library-4-Medium-768-480.webp 480w,/assets/img/posts/assets-25-img-library-4-Medium-768-800.webp 800w,/assets/img/posts/assets-25-img-library-4-Medium-768-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/assets-25-img-library-4-Medium-768.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A few of the large print books at the library. It is interesting how they use different font size and styling. </div> </div> </div> <p>This was my first time attending ASSETS, which has a long history since 1994. the conference is much smaller than CHI (which it sprung out of), and was single track until last year. This year though, it shifted to a dual track structure‚Äîsplit between two rooms. However, the entire conference took place on the same floor of the hotel, which was very comfortable. Since everyone is on the same floor, between both of the rooms, there was plenty of opportunities to chat and connect with other researchers and attendees.</p> <p>It was so inspiring to see so many people interested in accessibility! Everyone is so passionate about their work and the impact they could have through their work; which is something I absolutely share. It was <strong>especially impactful</strong> to me to connect and chat with other researchers with disabilities. As a researcher with a disability myself, it was very important to see how many others pursue research despite everything! All throughout my life, almost everything is some kind of a struggle, but to me, this is what makes life so interesting, overcoming these difficulties‚Äîand I‚Äôm not the only one. In a nutshell, to me, ASSETS feels like home.</p> <p>Another wonderful thing is that I was able to connect with past collegues from The University of Texas at Austin (UT Austin). I spent a summer there as a visiting researcher, and it was such a pleasure to be able to meet again and reunite! Especially, I am glad to see <a href="https://amypavel.com/">Prof. Amy Pavel</a>, who hosted my stay at UT Austin there. Amy co-authored two papers with me for ASSETS 2025, <a href="https://veasyguide.github.io/">VeasyGuide</a> and <a href="https://dl.acm.org/doi/10.1145/3663547.3746401">Task Mode</a>, which is a project by <a href="https://ananyagm.com/">Ananya</a>, another amazing researcher from UT Austin.</p> <div class="row justify-content-center"> <div class="col-md-8"> <div class="row mt-3"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/assets-25-img-conference-1-Medium-768-480.webp 480w,/assets/img/posts/assets-25-img-conference-1-Medium-768-800.webp 800w,/assets/img/posts/assets-25-img-conference-1-Medium-768-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/assets-25-img-conference-1-Medium-768.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Group picture with my collegues fromn UT Austin. So glad to reunite with you all there! </div> </div> </div> <p>Before I move on to share my presentation experience, it‚Äôs important to mention that even though it was my first ASSETS, I was able to co-author another full paper (Task Mode) and a poster! The poster was lead by <a href="https://veronicapim.github.io/">Veronica</a>, who is an amazing researcher from The University of Michigen. It was a delight working on this topic with Veronica. People with ADHD are often left behind, with not much research conducted on ways to help, assist, or improve their daily life. This is especially true for professionals with ADHD, for instance, with managing online communication via email.</p> <div class="row justify-content-center"> <div class="col-md-8"> <div class="row mt-3"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/assets-25-img-conference-2-Medium-768-480.webp 480w,/assets/img/posts/assets-25-img-conference-2-Medium-768-800.webp 800w,/assets/img/posts/assets-25-img-conference-2-Medium-768-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/assets-25-img-conference-2-Medium-768.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Our poster presentation at ASSETS, titled: "A Longitudinal Autoethnography of Email Access for a Professional with Chronic Illness and ADHD: Preliminary Insights". </div> </div> </div> <p>Now, <em>about VeasyGuide!</em> The presentation and interaction with the listeners was very impactful for me. I got so many wonderful questions during and after the talk! I truly appreciate everyone who watched, asked questions, and provided feedback on this work. Below I put the <strong>video recording</strong> of the talk and the transcriptions of the <strong>Q&amp;A session</strong>. There are so many more things to do to improve online learning accessibility for low-vision learners!</p> <div id="recording" class="row justify-content-center mt-3"> <div class="col-12 col-md-8"> <div class="video-wrapper-16x9"> <iframe src="https://www.youtube.com/embed/3eD-7JJtlLY" class="responsive-iframe" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"/> </div> <div class="caption"> Recording of the VeasyGuide presentation at ASSETS 2025. Closed captions are available in English. </div> </div> </div> <p>I truly appreciate the enthusiasm and interest of people in VeasyGuide. We got some great questions during the session, and I am happy to share them here.</p> <blockquote> <p><strong>Q1:</strong> I‚Äôm interested in how you use computer vision to recognize the different actions. Were there any actions that were harder or easier to pick up?</p> </blockquote> <p>So I can quickly go over the recognition. We divide the video into portions, less than one second long. And for each portion, we look at the front and last frame. Then we find the differences between them. Through that, we can detect contours of those differences. And over time, when we create these contours over time for many different, like, frame windows, we can basically create this graph that we connect based on proximity of space and time. So different contours can be connected based on those measurements. And that‚Äôs how we create edges.</p> <p>We call this the region of change graph. And over time, we can use that and connected component analysis to detect those visual activities that stay consistent. So in our work, some of activities were a bit more difficult. For instance, fast cursor movements. With fast cursor movements, we detect this, but we might not be able to connect it as one activity because it covers a very wide range in the slide over a short period of time.</p> <p>Also, we found that because of visual artifacts with compression, that while we do clean up some stuff, some visual artifacts were detected falsely as activities. So these are kind of some of the difficulties that we have with the pipeline. Thank you for your question.</p> <blockquote> <p><strong>Q2:</strong> So I think you mentioned that there‚Äôs customization functionalities for this tool. I think that‚Äôs great, especially given how much variation there is across people‚Äôs vision conditions and cognitive patterns. But I was wondering, like, how much did you notice people use that and is it different across individuals or even like within individuals?</p> </blockquote> <p>So since the user study of VeasyGuide, of course, is time limited, we couldn‚Äôt test a lot of different long videos for the same users. But we did notice a lot of different usage in personalization. For instance, we found that for users with narrow field of vision, peripheral vision loss, they used one feature that we added through the co-design study, which is an animation. So when activity shows up, it can grow and shrink. And they used that and found it very helpful.</p> <p>But for users with photosensitivity, for instance, this was not very useful and actually kind of harmful as well, because of the changes in brightness from the growing and shrinking of the highlight itself. And other users used color inversion, or changed the colors of the highlights and chose different visual annotations, like the pointer or the cursor indicator. So we found a lot of differences between users, and have more details in the paper.</p> <blockquote> <p><strong>Q3:</strong> You mentioned the eventual ability to be able to use your own videos for this. Is there a pre-processing step for the videos? Or is this being done essentially live as the video is broadcasting?</p> </blockquote> <p>So we have a section in our paper that we detail how we make VeasyGuide available for live content as well. And there are several ways to do that. But right now, VeasyGuide relies on a processing stage. So in our plan, it would be doing the processing on the server side without retaining the video, and then having the processing available on the client side, which should not take too long.</p> <p>I am looking forward to ASSETS 2026 in Portugal! ‚ú®</p>]]></content><author><name>Yotam Sechayk</name></author><category term="conference"/><category term="accessibility"/><category term="ASSETS"/><category term="e-learning"/><category term="low-vision"/><category term="ADHD"/><category term="award"/><summary type="html"><![CDATA[Recapping my experience presenting VeasyGuide at ASSETS 2025, which got a best paper honorable mention! Read about the conference and watch the recording of my talk. VeasyGuide is making communication between instructors and students in slide-based presentation videos accessible for low-vision learners.]]></summary></entry><entry><title type="html">AT and me: An interview with Yotam Sechayk</title><link href="https://tomfluff.github.io/blog/2025/p2t-yotam-sechayk/" rel="alternate" type="text/html" title="AT and me: An interview with Yotam Sechayk"/><published>2025-08-26T14:00:00+00:00</published><updated>2025-08-26T14:00:00+00:00</updated><id>https://tomfluff.github.io/blog/2025/p2t-yotam-sechayk</id><content type="html" xml:base="https://tomfluff.github.io/blog/2025/p2t-yotam-sechayk/"><![CDATA[<p>At Paths to Technology, we are passionate about assistive technology and even more passionate about centering the perspectives of students with visual impairment that use it in their own lives. This includes students of all ages and academic levels‚Äî even PhD students!</p> <p>In this Q&amp;A-style interview, P2T intern (and PhD student) Veronica Lewis interviews accessibility researcher Yotam Sechayk, a PhD candidate at University of Tokyo studying Creative Informatics. Yotam has albinism, and his research interests include assistive technology and accessibility for low vision access. Some of his current projects include VeasyGuide, a tool designed to make lecture videos easier to follow along with, as well as another project for making graphs and charts easier to see. When he isn‚Äôt studying, Yotam is often thinking about his next trip‚Äî he has been to over twenty countries and loves exploring new places during his solo travels. His experiences as a student with low vision profoundly shape his research and the ways he interacts with technology, and this post is filled with tons of tips, resources, and ideas for exploring accessibility research. How would you describe your visual impairment?</p> <p>I have albinism (plus nystagmus and photophobia), so low vision is something I have lived with for my entire life. It is very difficult for me to explain to other people what my usable vision looks like, because I don‚Äôt have a comparison for how I am supposed to see.</p> <p>The most useful way I can think of to explain my vision is to compare two videos, where one is in a 4K super high resolution and the other video is in 480p. You can still see things, but you are missing out on a lot of the details. People ask me if my vision is blurry, and I tell them that I have no idea. I mean, compared to blur effects, my vision is not the same, but I really do not know since my vision has always been like this. Did you know anyone else with albinism/low vision growing up?</p> <p>Not really. I am the only person in my immediate family with albinism, so I have mostly been on my own when it comes to figuring things out. When I was in primary school and junior high school, I attended a yearly summer program where I would meet other kids that had low vision or even albinism. They were close in age to me or a few years older/younger, but I didn‚Äôt have any role models with albinism or anyone that I could really learn from or get tips from. How do you access information? Do you mostly access things visually?</p> <p>I read large print, watch movies, and play video games, but reading can be very exhausting, and I read more slowly. So I will also use audiobooks or text-to-speech to make it easier to read, especially when reading papers for my research. I rely on text-to-speech engines more often nowadays; the technology is much more accessible now than it was when I was younger. But I am really glad I took the time to learn how to read print materials, even if listening is easier, because you don‚Äôt always have access to text-to-speech to read something. What kind of technologies and skills did you use as a young student?</p> <p>Other than glasses or sunglasses, the first assistive technology tool I remember using was a dome magnifier in primary school‚îÄ it looked like half a sphere. It was very convenient and comfortable to read with, more than a lot of the digital tools that are around nowadays. It is only inconvenient when you get to the very edge of the page because it is harder to put the magnifying glass on the edge. When I was studying for my bachelor‚Äôs degree, I also had a distance video magnifier I would use to see the board called the Transformer, but the camera quality back then was not very good (this was over ten years ago). 3.8-inch dome magnifier positioned on top of a history textbook, providing 5x magnification A 3.8-inch dome magnifier that provides 5x magnification</p> <p>In primary school, I would have all my assignments enlarged on A3 paper and would sit in the front row of the class. However, I had to remind teachers to write larger on the board frequently, and it was very rare that teachers would remember to enlarge any handouts. I can probably count on two hands the number of times that I did not have to do it myself. Most times, I would have to leave the classroom to enlarge my own work on the copier. I would often lose focus because I had to go to the principal‚Äôs office or the secretary‚Äôs office to use the copier, then come back to class and try to re-focus on doing the assignment or taking the test.</p> <p>Lastly, one of the things I need in places with windows are curtains, because the light can be too bright for me. I would have loved to have complete control over how much light there is in the world, but I don‚Äôt have that. Curtains make it easier for me to see by blocking some of the light, especially in classrooms. My primary school didn‚Äôt have curtains, and also refused to buy them. So my family purchased curtains on our own, and every year when I moved to a new class, my family would come and take down the curtains and put them up in my new class. It‚Äôs important not to get discouraged just because we face some barriers. Self-advocate, find ways to create an environment that works for you, and build a supportive community of family, friends, and people that understand you. It‚Äôs important to learn your own accessibility needs and to learn how to make things accessible for you. What assistive technology and accessibility features do you use now?</p> <p>I use several different tools and features on my Windows laptop, Windows desktop computer, and on my iPhone. I prefer the desktop because the monitor is bigger. I mostly use a single monitor, but there can be some situations where it is helpful to have two monitors to read two files with large print. But I cannot switch back and forth between monitors very quickly with my eyes, so one monitor is enough for me.</p> <p>My ‚Äútech toolbox‚Äù comes down to three main components: magnification, text-to-speech, and dark mode. Also recently, like many people, I use AI chat and AI agents, which help with summarizing or understanding things like large amounts of text. Screen magnification</p> <p>For screen magnification, I use Windows Magnifier with a full screen view. I also use Zoom on my iPhone along with a large text size and display size. I also use the Magnifier app that connects to my phone camera. It is really helpful for reading a menu behind a counter at a restaurant or for reading nutrition details on products. I have these features enabled with [AssistiveTouch] so I can have a button on my screen to quickly access magnification. Text-to-speech</p> <p>For text-to-speech, I use a free tool called BalaBolka that has a lot of features. It gives you the ability to create shortcuts for specific things. For example, when you select text anywhere, you can click the shortcut, it will copy the text, and read that text out loud. As long as you can copy it, BalaBolka can read it. It works in combination with the Microsoft Edge speech engines, so I can read basically any language and choose voices, customize the pitch, speed, and all sorts of things. I created a slew of keyboard or mouse shortcuts to quickly change the rate, start reading, stop reading, all on-the-fly. It is very, very, useful. I am not using all of the BalaBolka features, but maybe I should explore them more‚Äî there is a feature that helps you train your reading speed too.</p> <p>I thought I would use [Speak Screen or Speak Text] more often on my iPhone, but I tend not to for two reasons. One is because a lot of people send audio messages these days, which is pretty nice. But text-to-speech is not as easily accessible to use as I would like. I have to swipe down with two fingers from the top of the screen, listen to it start from the beginning, click next, next, next, next, and navigate, then maybe I clicked next too many times and I have to go back and try to find my place. And it seems that I can‚Äôt easily change the speed either. I really wish text-to-speech worked better on iPhone. Something I really like about Android is that you can click the [accessibility shortcut] on your Home Screen and select an area on your screen, like a bounding box, and it reads the content inside of that box. I think that is very useful. Dark mode</p> <p>For dark mode, I use the Dark Reader web extension to turn websites into dark mode. It‚Äôs not perfect, but it‚Äôs pretty good. I find it much easier to see white text on a black background. I also use color filters on Windows, like color inversion. Inverting colors is my go-to filter when dark mode doesn‚Äôt work. What has been the most challenging assistive tech tool you have had to learn?</p> <p>There are some assistive technology tools that I would have liked to be able to use, but don‚Äôt, because they are either too much for me or I can‚Äôt customize it. For example, a screen reader can be very useful for me in some situations, but it is hard for me to select specific segments of text. Text-to-speech is much more targeted.</p> <p>Another tool I used to use a lot was this custom CSS plugin for a web browser‚Äî CSS is a styling scripting language for the web. I could write short snippets that I could use to magnify and change the font sizes, colors, and things like that on websites. I could just enlarge the title of a page, or just the content, or change the colors. This has great potential for websites you use frequently, but it can be challenging to learn CSS and how to use it.</p> <p>It can be challenging to try a new tool, but in the long run it can be very useful. So while it is difficult to learn something new at first, the benefits can be far greater than the difficulty in the beginning. A comparison of two screenshots showing an excerpt of this post. Screenshot 1 has the default CSS values of 2.5rem for heading and 1rem for body text. Screenshot 2 has a CSS snippet added for ‚Äú.main font-size: 30px‚Äù, changing all text on the page to the same larger size, equivalent to about 22 pt font. Screenshot 1 has the default CSS values of 2.5rem for heading and 1rem for body text (40px and 16 px). Screenshot 2 has a CSS snippet added for ‚Äú.main font-size: 30px‚Äù, changing all text on the page to the same larger size What is your workflow for programming/coding?</p> <p>I use Visual Studio Code with a dark theme, and I enlarged the interface size and font size as well. The most common programming languages I use are Python, TypeScript, and R, but sometimes I also use C# or C++.</p> <p>Some programming languages like C++ are very text-heavy, which can be overwhelming. There are other languages that are less heavy on text and have more spacing. One common difficulty I experience is with languages that have a lot of indentation. For example, with HTML, the element tree can get pretty deep and indent so much that I end up seeing only a few words before it wraps to the next line. It can be very annoying. Eight levels of nested HTML in Visual Studio Code. The text ‚ÄúThis message is nested 8 levels deep!‚Äù is split across three lines with 11-13 characters on each line Eight levels of nested HTML in Visual Studio Code. The text ‚ÄúThis message is nested 8 levels deep!‚Äù is split across three lines with 11-13 characters on each line What is a strategy or tech trick that has really helped you?</p> <p>My mouse has two extra buttons on the side near where the thumb is, so I configured these buttons to activate the shortcut keys on BalaBolka to read any text I select. One of the buttons has the shortcut key for this text-to-speech engine, so I can select text, then click that shortcut key on the mouse to listen to the text read out loud. The other button next to it makes it stop talking. So I can very quickly and easily select text, like triple-clicking to select a paragraph, and then clicking the first mouse button to read it out loud or the other one to stop reading. It‚Äôs a great workflow for convenience. Example of side buttons on mouse How do you access information for your courses/research?</p> <p>I mostly use my computer for all of my classes and research, so I spend a lot of time using a screen magnifier, using dark mode, and then use text-to-speech when I am studying on my own. I don‚Äôt have face-to-face classes frequently, but those can be very challenging because I just can‚Äôt see the slides, and the instructors don‚Äôt always share their slides. Also, when instructors use the whiteboard it can be especially challenging, because even if you remind people to write bigger, they might write, like, one sentence, and then you can see their handwriting slowly shrinks down in size as they keep writing.</p> <p>I take online classes, which can be more accessible, but they can still be problematic because the instructors will use a pointer or a pen that is super small or thin and hard to see. And the contrast is sometimes not good enough either but you can‚Äôt really stop them in the middle of the class and ask them to explain what they are writing because it is hard to read. But at least on Zoom I can take screenshots and read them later.</p> <p>When people with low vision are in an online class, they always have to be alert. Like when the instructor is pointing at something and using verbal cues like ‚Äúover here.‚Äù Or if there is a pause in their speech, they might be sketching or drawing something. It‚Äôs very exhausting, and can prevent you from calmly learning, studying, and following along in class because you think so much about access, not so much learning. This was the motivation to my recent work VeasyGuide which tries to address this exact problem. How do these experiences influence your research?</p> <p>I am very passionate about accessibility because I can see a lot of the gaps in accessible designs. For years, I have wondered why we have super advanced cameras on our phones but all of the specialty accessibility tools I was using in school had these really low quality cameras despite being super expensive. And then they wouldn‚Äôt get updates. Accessibility can be so much more, and this line of research is very important and very personal to me. I want to identify problems, create solutions, and ensure that whatever I develop is made available for people. I want to give people access to the technology and tools that I develop.</p> <p>My experience has shown me that the needs of people with low vision are very individual, and can also change depending on the situation. Everyone has their own way of dealing with visual information, and I want to support that instead of replacing it. So in VeasyGuide, I don‚Äôt replace pointing, marking, and sketching in presentation videos, I make them easier to see and notice, so people don‚Äôt have to spend energy on trying to locate them or find ways to zoom in. I want to narrow the gap between the experiences of sighted people and low vision people, and make it easier for them to access visual information.</p> <p>Basically, I don‚Äôt want to keep people from using their vision, I want to just support people and their existing ways. I remember when I had to use the video magnifier in university, it was a clunky device I had to carry with me. Everyone could see that I was using it, and I felt like I stood out. There is nothing wrong with that feeling, but the best thing would have been if there was a way to make things on the board easier to see for everyone. Like for example, if the school had cameras pointed at the board or could stream it so people could see it on their own screens. I would not need to use the magnifier then. I want to create tools in ways that are accessible from the get-go, providing ease of access for everyone. Do you use the technologies you create in your own workflows?</p> <p>Yes, for sure! VeasyGuide was actually motivated by one of the lecturers here at the University of Tokyo. Listening to the lectures was very cognitively demanding due to several factors. First, the speech wasn‚Äôt clear for a few reasons, like the volume, the pace, or the way someone might rephrase something multiple times, which can make it harder to follow along. Then the slides were a white background with black text, and it was very bright. And they used a pointer that was basically the size of one pixel so it was very difficult to see, and the sketches were also really thin. And then the content and topic itself was also difficult, so it was really exhausting to watch the lectures. VeasyGuide makes it much easier to notice these pointers or sketches, zoom in, and follow along. VeasyGuide will be available publicly as a web application by October 2025. VeasyGuide interface screenshots. Taken from https://veasyguide.github.io/ What advice would you have for others who are interested in research and/or accessibility?</p> <p>First, always be curious, inquisitive, and interested about why and how things are the way they are, and be motivated to change things. So many people give up because maybe they don‚Äôt know if something can be solved or not. I come from the perspective of nothing is impossible, the sky‚Äôs the limit, asking ‚Äúwhat if I had everything in my power, what could I do?‚Äù Then it‚Äôs just about making a small step towards that.</p> <p>Another important thing is being creative, which is easy to say but more difficult to do. Solutions don‚Äôt have to be complex or complicated. Good solutions are simple and creative ones. One way to practice inducing creativity is to give yourself a forced limitation. For example, one limitation could be not changing how people navigate or not converting content to a new format‚Äîwhich is the limitation I posed on myself for VeasyGuide. So that is an example of ways to force yourself to think creatively. But even when you limit yourself, still think from the perspective of ‚Äúthe sky is the limit.‚Äù</p> <p>For accessibility research, one very important component is to be interested in people and their experiences. Maybe it is kind of obvious, but to create accessible solutions, it is very, very important that you are interested in the experiences of people. Like, maybe you have some solution that might work in your mind, but if other people have a different experience, it is important to listen to those experiences and listen to the way they use things. It is very easy to think that ‚Äúoh, they are just not using it right,‚Äù but you also have to consider why they aren‚Äôt using it the way you intended. Always be interested in people and their experiences.</p> <p>In a sense, we are all researchers. I don‚Äôt think many people live their life without trying different things, because a lot of people want to make their life easier, better, nicer, and more comfortable. But people with disabilities are especially great researchers, because you always have technology that you have to try, or you are trying to find strategies or workflows that work for you. You do trial and error, you do experiments with yourself, and that is essentially research. It took me a very long time to be able to reach a point where my workflow is comfortable for me, and there are many things that I am still learning. But I have curiosity, creativity, and a passion for making my life better. What excites you the most about the future of accessibility and assistive technology?</p> <p>I envision a future where technology is made accessible from the start. One of the ways to achieve that is through the involvement of people with disabilities or people that have specific access needs from the inception of new technology. Also, involving a lot of personalized interfaces or customizable experiences where users can change different settings and control how things operate or behave will contribute to accessibility. For a recent example, AI agents can generate text in a way that you like; maybe you want more, or less text, maybe you want to explain this one thing a bit more, or maybe you want to explain something else. I am very much looking forward to the future where everything is designed with accessibility in mind, and personalization plays a big role in that.</p> <table> <tbody> <tr> <td>Thank you to Yotam Sechayk for participating in this interview and sharing so much information! To connect with Yotam and learn more about this research, visit his website at Yotam Sechayk</td> <td>GitHub</td> </tr> </tbody> </table>]]></content><author><name></name></author><category term="external"/><category term="interview"/><category term="assistive-technology"/><category term="accessibility"/><summary type="html"><![CDATA[Veronica Lewis interviews Yotam Sechayk, a University of Tokyo PhD candidate with albinism who studies low-vision accessibility. The discussion covers his assistive tech projects‚Äîsuch as VeasyGuide for lecture videos‚Äîand how his personal experiences shape his research, and his passion for solo travel.]]></summary></entry><entry><title type="html">Smart Replay at WISS 2023 Recap and Helpfeel Award üèÜ</title><link href="https://tomfluff.github.io/blog/2023/wiss-2023-helpfeel-award/" rel="alternate" type="text/html" title="Smart Replay at WISS 2023 Recap and Helpfeel Award üèÜ"/><published>2023-12-01T01:00:00+00:00</published><updated>2023-12-01T01:00:00+00:00</updated><id>https://tomfluff.github.io/blog/2023/wiss-2023-helpfeel-award</id><content type="html" xml:base="https://tomfluff.github.io/blog/2023/wiss-2023-helpfeel-award/"><![CDATA[<p>On a backdrop of the end of 2023, surrounded by snowy mountain ranges, I had the opportunity to present our work <em>‚ÄúSmart Replay: e„É©„Éº„Éã„É≥„Ç∞ÂãïÁîª„Å´„Åä„Åë„ÇãË¶ñË¶öÁöÑ„ÉªÊôÇÈñìÁöÑ„Ç¢„ÇØ„Çª„Ç∑„Éì„É™„ÉÜ„Ç£„ÅÆÂêë‰∏ä‚Äù</em> at <strong>WISS 2023 (Workshop on Interactive Systems and Software)</strong>. This was my very first oral presentation of a paper at a conference‚Äîa memorable milestone in my research journey.</p> <p>To our delight, our project on e-learning accessibility received the <strong>Helpfeel Award</strong>, recognizing both the technical contribution and the broader vision of making video learning more inclusive for people with disabilities.</p> <div class="row justify-content-center"> <div class="col-md-10"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/wiss-23-img-1-480.webp 480w,/assets/img/posts/wiss-23-img-1-800.webp 800w,/assets/img/posts/wiss-23-img-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/wiss-23-img-1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/wiss-23-img-2-480.webp 480w,/assets/img/posts/wiss-23-img-2-800.webp 800w,/assets/img/posts/wiss-23-img-2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/wiss-23-img-2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Receiving the Helpfeel award at WISS 2023. </div> </div> </div> <p>The reviewers and award committee emphasized how the work not only tackled practical issues learners face when using video platforms, but also reflected a broader commitment to accessibility and user experience. Their comments encouraged us to keep pushing toward real-world deployment and impact. Read more on this <a href="https://blog.notainc.com/entry/2023/12/11/165959">Helpfeel blog post</a>.</p> <p>WISS itself is a wonderful conference‚Äîa local but vibrant gathering of the HCI community in Japan. It was held this year in <strong>Kobuchizawa</strong> at the Royal Hotel ÂÖ´„É∂Â≤≥, surrounded by mountains and stunning scenery. The atmosphere was inspiring, both academically and personally.</p> <p>You can catch a glimpse of the area in <a href="https://www.youtube.com/watch?v=0RsLz1O_5lM">this short video</a>:</p> <div class="row justify-content-center mt-3"> <div class="col-12 col-md-8"> <div class="video-wrapper-16x9"> <iframe src="https://www.youtube.com/embed/0RsLz1O_5lM" class="responsive-iframe" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"/> </div> </div> </div> <p>For anyone curious, the recording of my talk is available on <a href="https://youtu.be/pWNfCc4Sz58?t=8210">YouTube</a>:</p> <div class="row justify-content-center mt-3"> <div class="col-12 col-md-8"> <div class="video-wrapper-16x9"> <iframe src="https://www.youtube.com/embed/pWNfCc4Sz58?amp;start=8210" class="responsive-iframe" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"/> </div> </div> </div> <p>If you‚Äôd like to dive deeper, you can read comments by conference attendees on the <a href="https://scrapbox.io/WISS2023/04_Smart_Replay:_e%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E5%8B%95%E7%94%BB%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E8%A6%96%E8%A6%9A%E7%9A%84%E3%83%BB%E6%99%82%E9%96%93%E7%9A%84%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B7%E3%83%93%E3%83%AA%E3%83%86%E3%82%A3%E3%81%AE%E5%90%91%E4%B8%8A">Scrapbox page</a> or check out all awardees on the <a href="https://www.wiss.org/WISS2023/award.html">official WISS website</a>.</p> <p>Overall, it was a deeply rewarding experience‚Äîpresenting in Japan, connecting with the local HCI community, and seeing our work recognized with an award. It gives me a lot of motivation for the next steps in this project. üí™</p>]]></content><author><name>Yotam Sechayk</name></author><category term="conference"/><category term="accessibility"/><category term="e-learning"/><category term="WISS"/><category term="award"/><summary type="html"><![CDATA[Recap of my presentation of 'Smart Replay' at WISS 2023, which also was my first WISS! A fun surprize was receiving the Helpfeel Award for improving accessibility in e-learning videos.]]></summary></entry></feed>